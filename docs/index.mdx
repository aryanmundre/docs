# What is Kindred

Kindred is a deterministic sandbox for testing AI agents that take actions. It runs agents against a controlled world, injects failures in a reproducible way, and evaluates behavior using explicit pass or fail rules.
We provided deterministic, reproducible evaluation for agents that call tools, mutate state, and make decisions. Evaluates behavior (tool calls + state), not just text.

## Designed for:

- Call tools or APIs
- Mutate state (databases, files, systems)
- Make decisions that affect outcomes
- Require reliability guarantees

## Not designed for:

- Simple chat completion evaluation
- Agents that only generate text
- Testing prompt variations without action
- Monitoring live production traffic

## What Kindred does not do

Kindred does not:

- Optimize prompts
- Monitor live production traffic
- Automatically fix agents
- Automatically run on pull requests
- Use LLM-based graders

Kindred is a pre-production reliability and evaluation system.

